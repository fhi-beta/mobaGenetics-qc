rule_stem = 'maf_removal_markers'
rule maf_removal_markers:   #Minor allele frequencies removal
    input:
        bedset = rules.update_rsids.output.bedset
    output:
        bedset=expand(str(tmpMod2/rule_stem)
                          + '{ext}', ext=['.bed','.bim','.fam']),
        callrates = expand(str(tmpMod2/rule_stem)
                          + '{ext}', ext=['.lmiss','.imiss']),
        results = report((resultPath/rule_stem).with_suffix(".yaml"),
                         category="Module 2 Core samples and infere pedigree",
                         caption=(resultPath/rule_stem).with_suffix(".rst")),
        plot = report((resultPath/rule_stem).with_suffix(".png"),
                      category="Module 2 Core samples and infere pedigree",
                      caption=(resultPath/rule_stem).with_suffix(".rst"))

    params:
        treshold = config['maf_thr']

    run:
        item_type = rule_info[rule]["rule type"]
        mqc.log(runlog, "Initial cleaning: Low minor allele frequencies removal(--maf)\n")
        inTrunk =  mqc.plinkBase(input.bedset[0])
        outTrunk =  mqc.plinkBase(output.bedset[0])

        subprocess.run([plinklocal,
                "--bfile",inTrunk,
                "--maf", str(params.treshold),
                "--out", outTrunk,      # previously named superclean_maf
                "--make-bed" ])
        dropouts = mqc.checkUpdates(inTrunk+".bim",outTrunk+".bim",cols = [0,1],
                                    sanityCheck = "removal", fullList = True) 
        dropouts.update(rule_info[rule])   # Metainfo and documentation about the rule
        dropouts["Treshold"] = params.treshold
        dropouts["Rule"] = rule
        mqc.saveYamlResults(output.results, dropouts)

        # call rates for maf will be maf_removal_markers.output.bedset imiss and lmiss
        # these will be reused later
        subprocess.run([plinklocal,
                "--bfile", outTrunk,
                "--missing",
                "--out", outTrunk ])

        mqc.plot_point_and_line(dropouts, outTrunk+".lmiss", output.plot,
                                column="F_MISS",ylabel="1 - missingness")


rule_stem = 'tmp_missing_genotype_samples'
rule missing_genotype_samples:   
    input:
        bedset = rules.maf_removal_markers.output.bedset
    output:
        bedset=expand(str(tmpMod2/rule_stem)
                          + '{ext}', ext=['.bed','.bim','.fam']),  # earlier called superclean_maf_mind
        results = report((resultPath/rule_stem).with_suffix(".yaml"),
                         category="Module 2 Core samples and infere pedigree",
                         caption=(resultPath/rule_stem).with_suffix(".rst"))
    params:
        treshold = config['mind_thr']

    run:
        item_type = rule_info[rule]["rule type"]
        mqc.log(runlog, "Missing genotype {item_type} (--mind)\n")
        inTrunk =  mqc.plinkBase(input.bedset[0])
        outTrunk =  mqc.plinkBase(output.bedset[0])
        # First extract temporary samples based on earlier filtered markers (maf_removal_markers)
        # Later these will be used to extract samples permanently (rule clean_samples:)
        mqc.missing_genotype_rate(rule,
                        inTrunk, outTrunk, sample=True, treshold=params.treshold,
                        result_file=output.results)
        

rule_stem = "perm_after_mind"
rule clean_samples:
    input:
        # This is for permanent removal - as it was wayback before sevaral removals
        perm_bedset = rules.maf_removal_markers.input.bedset,
        # This is based on earlier temporary filters
        bedset = rules.missing_genotype_samples.output.bedset,
        # While this is callrates we computed at the --maf stage
        callrates = rules.maf_removal_markers.output.callrates
    output:
        perm_bedset=expand(str(tmpMod2/'missing_genotype_samples')
                          + '{ext}', ext=['.bed','.bim','.fam']),
        results = report((resultPath/rule_stem).with_suffix(".yaml"),
                         category="Module 2 Core samples and infere pedigree",
                         caption=(resultPath/rule_stem).with_suffix(".rst")),
        plot = report((resultPath/rule_stem).with_suffix(".png"),
                      category="Module 2 Core samples and infere pedigree",
                      caption=(resultPath/rule_stem).with_suffix(".rst"))
    
    run:
        oldPermTrunk =  mqc.plinkBase(input.perm_bedset[0])   # what we had
        callRateTrunk = mqc.plinkBase(input.callrates[0])

        inTrunk =  mqc.plinkBase(input.bedset[0])             # what we temporary filtered
        permTrunk =  mqc.plinkBase(output.perm_bedset[0])     # what we are making

        # PERMANENT removal of very-missing individuals from FULL dataset
        subprocess.run([plinklocal,
                "--bfile",oldPermTrunk,
                "--keep",inTrunk + ".fam", # keeping those samples that just passed the --mind threshold
                "--out", permTrunk,        # earlier called full_mind
                "--make-bed" ])
        dropouts = mqc.checkUpdates(oldPermTrunk+".fam", permTrunk+".fam",cols = [0,1],
                                    sanityCheck = "removal", fullList = True)

        dropouts.update(rule_info[rule])   # Metainfo and documentation about the rule
        dropouts["Rule"] = rule
        mqc.saveYamlResults(output.results, dropouts)

        # call rates for samples were previously computed, we now know how many actually got cut
        mqc.plot_point_and_line(dropouts, callRateTrunk+".imiss", output.plot,
                                column="F_MISS",ylabel="1 - missingness")

     
rule_stem = 'tmp_missing_genotype_markers' # used for outputfilenames        
rule missing_genotype_markers:
    input:
        # This is based on earlier temporary filters - the same that we used to remember samples permanently
        bedset = rules.missing_genotype_samples.output.bedset
    output:
        bedset=expand(str(tmpMod2/rule_stem)
                          + '{ext}', ext=['.bed','.bim','.fam']),
        results = report((resultPath/rule_stem).with_suffix(".yaml"),
                         category="Module 2 Core samples and infere pedigree",
                         caption=(resultPath/rule_stem).with_suffix(".rst")),
        plot = report((resultPath/rule_stem).with_suffix(".png"),
                      category="Module 2 Core samples and infere pedigree",
                      caption=(resultPath/rule_stem).with_suffix(".rst"))
    params:
        treshold = config['geno_thr']
    run:
        item_type = rule_info[rule]["rule type"]
        mqc.log(runlog, "Missing genotype {item_type} (--geno)\n")
        inTrunk =  mqc.plinkBase(input.bedset[0])
        outTrunk =  mqc.plinkBase(output.bedset[0])

        dropouts = mqc.missing_genotype_rate(rule,
                        inTrunk, outTrunk, sample=False, treshold=params.treshold,
                        result_file=output.results,
                        plot_file=output.plot)

        
rule_stem = 'tmp_exclude_non-autosomal+unplaced_markers' # used for outputfilenames        
rule exclude_unplaced_and_non_autosomal_markers:
    input:
        # This is based on earlier temporary filters - the same that we used to remember samples permanently
        bedset = rules.missing_genotype_markers.output.bedset
    output:
        bedset = expand(str(tmpMod2/rule_stem)+'{ext}', ext=['.bed','.bim','.fam']),
        results = report((resultPath/rule_stem).with_suffix(".yaml"),
                         category="Module 2 Core samples and infere pedigree",
                         caption=(resultPath/rule_stem).with_suffix(".rst"))
    run:
        item_type = rule_info[rule]["rule type"]
        mqc.log(runlog, "Excluded unplaced and non-autosomal {item_type} (--autosome)\n")
        inTrunk =  mqc.plinkBase(input.bedset[0])
        outTrunk =  mqc.plinkBase(output.bedset[0])
        subprocess.run([plinklocal,
                "--bfile",inTrunk,
                "--autosome",                     # identifies markers
                "--out", outTrunk,                # called superclean_autosomal
                "--make-bed" ])

        dropouts = mqc.checkUpdates(inTrunk+".bim", outTrunk+".bim",cols = [0,1],
                                    sanityCheck = "removal", fullList = True) 
        dropouts.update(rule_info[rule])   # Metainfo and documentation about the rule
        dropouts["Rule"] = rule

        mqc.saveYamlResults(output.results, dropouts)

rule_stem = 'tmp_hwe_filtered_markers' # used for outputfilenames
rule hardy_weinberg_filtered_markers:
    input:
        # This is based on earlier temporary filters - the same that we used to remember samples permanently
        bedset = rules.exclude_unplaced_and_non_autosomal_markers.output.bedset
    output:
        bedset=expand(str(tmpMod2/rule_stem) + '{ext}', ext=['.bed','.bim','.fam']),
        results = report((resultPath/rule_stem).with_suffix(".yaml"),
                         category="Module 2 Core samples and infere pedigree",
                         caption=(resultPath/rule_stem).with_suffix(".rst")),
        plot = report((resultPath/rule_stem).with_suffix(".png"),
                         category="Module 2 Core samples and infere pedigree",
                         caption=(resultPath/rule_stem).with_suffix(".rst"))        
    params:
        treshold = config['hwe_thr']
    run:
        item_type = rule_info[rule]["rule type"]
        mqc.log(runlog, "Missing Hardy-Weinberg filtering {item_type} (--hwe)\n")
        inTrunk =  mqc.plinkBase(input.bedset[0])
        outTrunk = mqc.plinkBase(output.bedset[0])

        mqc.low_hwe_rate(rule, inTrunk, outTrunk, treshold=params.treshold,
                     hwe_switches = ["--hardy"],
                     result_file = output.results, plot_file=output.plot)

rule_stem = 'tmp_excluded_strand_amb_markers' # used for outputfilenames
rule exclude_strand_ambigious_markers:
    input:
        # This is based on earlier temporary filters 
        bedset = rules.hardy_weinberg_filtered_markers.output.bedset
    output:
        bedset=expand(str(tmpMod2/rule_stem) + '{ext}', ext=['.bed','.bim','.fam']),
        results = report((resultPath/rule_stem).with_suffix(".yaml"),
                         category="Module 2 Core samples and infere pedigree",
                         caption=(resultPath/rule_stem).with_suffix(".rst"))
    run:
        item_type = rule_info[rule]["rule type"]
        mqc.log(runlog, "Excluding ambigious {item_type} (GC/CG/AT/TA\n")
        inTrunk =  mqc.plinkBase(input.bedset[0])
        outTrunk =  mqc.plinkBase(output.bedset[0])

        mqc.exclude_strand_ambigious_markers(inTrunk, outTrunk, plinklocal)  
        dropouts = mqc.checkUpdates(inTrunk+".bim", outTrunk+".bim",cols = [0,1], sanityCheck = "removal", fullList = True) 
        dropouts.update(rule_info[rule])   # Metainfo and documentation about the rule
        dropouts["Rule"] = rule
        mqc.saveYamlResults(output.results, dropouts)

rule_stem = 'tmp_high_ld_excluded_markers' # used for outputfilenames
rule exclude_high_ld_markers:
    input:
        # This is based on earlier temporary filters 
        bedset = rules.exclude_strand_ambigious_markers.output.bedset,
        high_ld_regions_hg19 = "../resources/high-ld-regions-hg19"
    output:
        bedset=expand(str(tmpMod2/rule_stem) + '{ext}', ext=['.bed','.bim','.fam']),
        results = report((resultPath/rule_stem).with_suffix(".yaml"),
                         category="Module 2 Core samples and infere pedigree",
                         caption=(resultPath/rule_stem).with_suffix(".rst"))
    run:
        item_type = rule_info[rule]["rule type"]
        mqc.log(runlog, rule_info[rule]["QC test"])
        inTrunk =  mqc.plinkBase(input.bedset[0])
        outTrunk =  mqc.plinkBase(output.bedset[0]) 


        subprocess.run([plinklocal,
                "--bfile",inTrunk,
                "--exclude", "range", input.high_ld_regions_hg19,    # identifies markers
                "--out", outTrunk,                                   # called superclean_no_ag_ct_ld before
                "--make-bed"  ])
        
        dropouts = mqc.checkUpdates(inTrunk+".bim", outTrunk+".bim",cols = [0,1], sanityCheck = "removal", fullList = True) 
        dropouts.update(rule_info[rule])   # Metainfo and documentation about the rule
        dropouts["Rule"] = rule
        mqc.saveYamlResults(output.results, dropouts)

rule_stem = 'tmp_prune_markers' # used for outputfilenames
rule prune_markers:
    input:
        # This is based on earlier temporary filters 
        bedset = rules.exclude_high_ld_markers.output.bedset,
    output:
        bedset=expand(str(tmpMod2/rule_stem) + '{ext}', ext=['.bed','.bim','.fam']),
        exclude_list = (tmpMod2/rule_stem).with_suffix(".prune.in"),  #called prune_markers_tmp.prune.in before
        results = report((resultPath/rule_stem).with_suffix(".yaml"),
                         category="Module 2 Core samples and infere pedigree",
                         caption=(resultPath/rule_stem).with_suffix(".rst"))
    params:
        prune_cmd = config["prune_cmd"].split()    # As plink will want a list
        
    run:
        item_type = rule_info[rule]["rule type"]
        mqc.log(runlog, rule_info[rule]["QC test"])
        inTrunk =  mqc.plinkBase(input.bedset[0])
        outTrunk =  mqc.plinkBase(output.bedset[0])
        
        subprocess.run([plinklocal,
                "--bfile", inTrunk,
                "--make-founders",
                 "--out", outTrunk]    # no bed-file prodused, just .prune.in (exclude_list)
                 + params.prune_cmd )  # note that we here add a list to another list ... 


        subprocess.run([plinklocal,
                "--bfile", inTrunk,
                "--extract", output.exclude_list,               
                "--out", outTrunk,                  # called superclean_pruned before
                "--make-bed" ])
        
        dropouts = mqc.checkUpdates(inTrunk+".bim", outTrunk+".bim",cols = [0,1],
                                    sanityCheck = "removal", fullList = True) 
        dropouts.update(rule_info[rule])   # Metainfo and documentation about the rule
        dropouts["Rule"] = rule
        mqc.saveYamlResults(output.results, dropouts)


rule_stem = 'ped_incons_prep' # used for outputfilenames
rule pedigree_inconsistence_prep:
    input:
        in_geno = rules.missing_genotype_markers.output.bedset,
        in_all= rules.clean_samples.output.perm_bedset,
        clean_snps = rules.prune_markers.output.exclude_list
    output:
        bedset=expand(str(tmpMod2/rule_stem) + '{ext}', ext=['.bed','.bim','.fam']),
        genome = (tmpMod2/rule_stem).with_suffix(".genome"),
        inferpedx = tmpMod2/"inferpedx.sexcheck",
        results = report((resultPath/rule_stem).with_suffix(".yaml"),
                         category="Module 2 Core samples and infere pedigree",
                         caption=(resultPath/rule_stem).with_suffix(".rst"))

    run:
        item_type = rule_info[rule]["rule type"]
        mqc.log(runlog, rule_info[rule]["QC test"])
        inGenoTrunk =  mqc.plinkBase(input.in_geno[0])
        outTrunk =  mqc.plinkBase(output.bedset[0])

  	# plink will recommend sex assignments based on X het and Y calls
        subprocess.run([plinklocal,
                "--bfile", inGenoTrunk,
                "--check-sex", "ycount",
                "--out", mqc.plinkBase(output.inferpedx)  ]) # local stem: don't want to overwrite logfiles

        # get PIHAT estimates
        subprocess.run([plinklocal,
                "--bfile", inGenoTrunk,
                "--extract", input.clean_snps,
                "--genome", "--min", "0.10",                 # not parametrized for now 
                "--out", outTrunk,                           # called inferped_pruned before
                "--make-bed" ])

        dropouts = mqc.checkUpdates(inGenoTrunk+".bim", outTrunk+".bim",cols = [0,1],
                                    sanityCheck = "remove", fullList = True) 
        dropouts.update(rule_info[rule])   # Metainfo and documentation about the rule
        dropouts["Rule"] = rule
        mqc.saveYamlResults(output.results, dropouts)


# This rule is still in shell-syntax.        
rule pedigree_fu_detector_solver:
    input:
        in_geno = rules.missing_genotype_markers.output.bedset,
        in_all = rules.clean_samples.output.perm_bedset,
        ped_pruned = rules.pedigree_inconsistence_prep.output.bedset,
        ped_pruned_pihat = rules.pedigree_inconsistence_prep.output.genome,
        ped_sexcheck = rules.pedigree_inconsistence_prep.output.inferpedx
    output:
        pheno_ok_flags = tmpMod2/'phenotypesOK.txt',  # A list of samples that have passed sanitycheck?
        # Under: INFERRED family info, SUPERCLEAN markers
  	inferped_pruned = expand(str(tmpMod2/'inferped_pruned') + '{ext}', ext=['.bed','.bim','.fam']) ,
        # Under  INFERRED family info, ALL markers
       	inferped_all = expand(str(tmpMod2/'inferped_all') + '{ext}', ext=['.bed','.bim','.fam']) ,
        Rfixed_fam = tmpMod2/"inferped_updated.fam",
    params:
        outdir = tmpMod2,
        resdir = resultPath,
	inferfam = config['infer_recfam'],
	inferbad = config['infer_badids']
    shell:
        """
        set -x
        # lets used trunks to mimic earlier behaviour by extracting truncts from input/output
        foo={input.in_geno[0]}
        inGenoTrunk=${{foo%\.*}}
        foo={input.in_all[0]}
        inAllTrunk=${{foo%\.*}}
        foo={input.ped_pruned[0]}
        pedPrunedTrunk=${{foo%\.*}}

        foo={output.inferped_pruned[0]}
        outPrunedTrunk=${{foo%\.*}}
        foo={output.inferped_all[0]}
        outAllTrunk=${{foo%\.*}}

        # There used to be a column extractor here, but it didn't work so gutorm removed it
        # the .genome file is not tab-separated). Remove this after test/confirm
 	# cut -f 2,4,8,10 input.ped_pruned_pihat > output.ped_pruned_pihat
        # We use the input.ped_pruned_pihat directlry in the R script later

	# # ERROR if fam files were different for PRUNED and ALL markers (can't update then)
       	diff $inAllTrunk.fam $pedPrunedTrunk.fam

	# R script for updating fam file
	# 1. input fam file
	# 2. pihat file
	# 3. PLINK's sexcheck results
	# 4. /media/local-disk2/helgeland/rotterdam1/inferred-pedigree/permanent_reconstruct-fam.txt
	# 5. /media/local-disk2/helgeland/rotterdam1/inferred-pedigree/permanent_bad-sample-IIDs.txt
	# 6. inferped_data.RData
	# 7. updated fam file  - The one we will later use
	# 8. flag file for individuals/samples
	Rscript {libdir}/inferped_FuckupDetectorAndSolver.R \
	    $pedPrunedTrunk.fam \
	    {input.ped_pruned_pihat} \
	    {input.ped_sexcheck} \
	    {params.inferbad} \
	    {params.inferfam} \
	    {params.resdir}/inferped_data.RData \
	    {output.Rfixed_fam} \
	    {output.pheno_ok_flags}

	# # produce bedset with ALL markers and INFERRED family info
       	cp $inAllTrunk.bed     $outAllTrunk.bed
       	cp $inAllTrunk.bim     $outAllTrunk.bim
	cp {output.Rfixed_fam} $outAllTrunk.fam

	# produce/modify bedset with PRUNED (pruned) markers by replacing earlier .fam file with fixed one
	# (inferped_pruned.bed and .bim were made by previous rule)
       	cp $pedPrunedTrunk.bed $outPrunedTrunk.bed
       	cp $pedPrunedTrunk.bim $outPrunedTrunk.bim
        cp {output.Rfixed_fam} $outPrunedTrunk.fam  

        """

rule document_pedigree_fu_detector_solver:
    input:
        in_all = mqc.plinkBase(rules.pedigree_fu_detector_solver.input.in_all[0]) + ".fam",
        out_all = mqc.plinkBase(rules.pedigree_fu_detector_solver.output.inferped_all[0]) + ".fam",
        in_pruned = mqc.plinkBase(rules.pedigree_fu_detector_solver.input.ped_pruned[0]) + ".fam",
        out_pruned = mqc.plinkBase(rules.pedigree_fu_detector_solver.output.inferped_pruned[0]) + ".fam",
    output:
        results_all = report((resultPath/"pedigree_fu_detector_solver_all").with_suffix(".yaml"),
                         category="Module 2 Core samples and infere pedigree",
                         caption=(resultPath/"pedigree_fu_detector_solver_all").with_suffix(".rst")),       
        results_pruned = report((resultPath/"pedigree_fu_detector_solver_pruned").with_suffix(".yaml"),
                         category="Module 2 Core samples and infere pedigree",
                         caption=(resultPath/"pedigree_fu_detector_solver_pruned").with_suffix(".rst")),       
    run:
        mqc.log(runlog, rule_info[rule]["QC test"])

        dropouts = mqc.checkUpdates(input.in_all, input.out_all,cols = [0,1],
                                    sanityCheck = "update", fullList = True) 
        dropouts.update(rule_info[rule])   # Metainfo and documentation about the rule
        mqc.saveYamlResults(output.results_all, dropouts)
        
        dropouts = mqc.checkUpdates(input.in_pruned, input.out_pruned,cols = [0,1],
                                    sanityCheck = "update", fullList = True) 
        dropouts.update(rule_info[rule])   # Metainfo and documentation about the rule
        dropouts["Rule"] = rule

        mqc.saveYamlResults(output.results_pruned, dropouts)

# Part of the earlier rule pcawhapmap:
rule_stem = "pedigree_fix_pruned"
rule pedigree_fix_pruned:
    input:
        bedset = rules.pedigree_fu_detector_solver.output.inferped_pruned,
    output:
        bedset = expand(str(tmpMod2/rule_stem) + '{ext}', ext=['.bed','.bim','.fam']),
        problems = (tmpMod2/rule_stem).with_suffix(".prblm"),
        results = report((resultPath/rule_stem).with_suffix(".yaml"),
                    category="Module 2 Core samples and infere pedigree",
                    caption=(resultPath/rule_stem).with_suffix(".rst")),
    benchmark:
        (tmpMod2/rule_stem).with_suffix(".benchmark")
        
    run:
        item_type = rule_info[rule]["rule type"]
        mqc.log(runlog, rule_info[rule]["QC test"])
        inTrunk =  mqc.plinkBase(input.bedset[0])
        outTrunk =  mqc.plinkBase(output.bedset[0])

        # Somewhere earlier, we left trace about problematic triads naming the families *prblm
        with open(output.problems, "w") as fil:
            subprocess.run(["grep", "prblm", inTrunk+".fam"], stdout=fil)

        subprocess.run([plinklocal,
                "--bfile", inTrunk,
                "--remove", output.problems,
                "--out", outTrunk, "--make-bed"  ])  # used to be called no_inferped_problems
        dropouts = mqc.checkUpdates(inTrunk+".fam", outTrunk+".fam",cols = [0,1],
                                    sanityCheck = "remove", fullList = True) 
        dropouts.update(rule_info[rule])   # Metainfo and documentation about the rule
        dropouts["Rule"] = rule
        mqc.saveYamlResults(output.results, dropouts)
                
# Reduce 1000 genome markers to the one already pruned and sorted out for moba
rule_stem = 'common_markers_moba_ref'
rule common_markers_moba_ref:
    input:
        bedset_ref = expand(config["1000_genomes_stem"] +'{ext}', ext=['.bed','.bim','.fam']),
        bedset_moba = rules.pedigree_fix_pruned.output.bedset
    output:
        bedset_ref = expand(str(tmpMod2/"pca_ref") + '{ext}', ext=['.bed','.bim','.fam']),
        bedset_moba = expand(str(tmpMod2/"pca_moba") + '{ext}', ext=['.bed','.bim','.fam']),
        marker_list = (tmpMod2/rule_stem).with_suffix(".txt"),
        tri_alleles = report((tmpMod2/rule_stem).with_suffix(".missnp"),
                             category="Module 2 1000Genomes prep",
                             caption=(resultPath/"pca_ref").with_suffix(".rst")),
        results_ref = report((resultPath/"pca_ref").with_suffix(".yaml"),
                             category="Module 2 1000Genomes prep",
                             caption=(resultPath/"pca_ref").with_suffix(".rst")),
        results_moba = report((resultPath/"pca_moba").with_suffix(".yaml"),
                              category="Module 2 1000Genomes prep",
                              caption=(resultPath/"pca_moba").with_suffix(".rst")),
    benchmark:
        (tmpMod2/rule_stem).with_suffix(".benchmark")
        
    run:
        item_type = rule_info[rule]["rule type"]
        mqc.log(runlog, rule_info[rule]["QC test"])
        inTrunk_ref =  mqc.plinkBase(input.bedset_ref[0])
        inTrunk_moba =  mqc.plinkBase(input.bedset_moba[0])
        outTrunk_ref =  mqc.plinkBase(output.bedset_ref[0])
        outTrunk_moba =  mqc.plinkBase(output.bedset_moba[0])
        triallelesTrunk =  mqc.plinkBase(output.tri_alleles) 

        # Common markers found in marker_list
        mqc.intersect_rsid(inTrunk_moba+".bim", inTrunk_ref+".bim",  output.marker_list)
        # Reduce both sets to the common markers
        subprocess.run([plinklocal,
                "--bfile", inTrunk_ref,
                "--extract", output.marker_list,            
                "--out", outTrunk_ref,
                "--allow-extra-chr",  # such as PAR1 ...
                "--make-bed" ])
        subprocess.run([plinklocal,
                "--bfile", inTrunk_moba,
                "--extract", output.marker_list,            
                "--out", outTrunk_moba,                           
                "--make-bed" ])
        # alas these two are not identical enough -
        # discover tri-allele  problems by dummy-merging
        subprocess.run([plinklocal,
                 "--bfile", outTrunk_ref,
                 "--bmerge", outTrunk_moba,
                 "--out", triallelesTrunk ])
        # ... And then remove these markers from both sets
        # fyi: plink will append inputfiles  by ~ ... since input/output have same name
        subprocess.run([plinklocal,
                "--bfile", outTrunk_ref,
                "--exclude", output.tri_alleles,            
                "--out", outTrunk_ref,                           
                "--make-bed" ])

        subprocess.run([plinklocal,
                "--bfile", outTrunk_moba,
                "--exclude", output.tri_alleles,            
                "--out", outTrunk_moba,                           
                "--make-bed" ])
        
        # Document the reduction for ref (1000 genomes)
        dropouts = mqc.checkUpdates(inTrunk_ref+".bim", outTrunk_ref+".bim",cols = [0,1],
                                    sanityCheck = "removal", fullList = False)
        dropouts.update(rule_info[rule])   # Metainfo and documentation about the rule
        dropouts["Rule"] = rule
        dropouts["Excluded markers"] = f"Common markers in {output.marker_list}, trialleles removed in {output.tri_alleles}"
        mqc.saveYamlResults(output.results_ref, dropouts)

        # Document the reduction for moba
        dropouts = mqc.checkUpdates(inTrunk_moba+".bim", outTrunk_moba+".bim",cols = [0,1],
                                    sanityCheck = "removal", fullList = False)
        dropouts.update(rule_info[rule])   # Metainfo and documentation about the rule
        dropouts["Rule"] = rule
        dropouts["Excluded markers"] = f"Common markers in {output.marker_list}, trialleles removed in {output.tri_alleles}"
        mqc.saveYamlResults(output.results_moba, dropouts)

# 7.1.2020 projecting moba data on this did not work. For now we merge the data.                        
# rule_stem = "pca_1kgp"               
# rule pca_1kgp:
#     input:
#         bedset = rules.common_markers_moba_ref.output.bedset_ref,
#     output:
#         ref_pcs=tmpMod2/rule_stem/'pcs_1kgp',
#         ref_eigenvec=tmpMod2/rule_stem/'eigenvec_1kgp',
#         ref_loadings=tmpMod2/rule_stem/'loadings_1kgp',
#         ref_eigenval=tmpMod2/rule_stem/'eigenval_1kgp',
#         ref_var_explained=tmpMod2/rule_stem/'var_explained_1kgp',
#         ref_meansd=tmpMod2/rule_stem/'meansd_1kgp',      
#     run:
#         item_type = rule_info[rule]["rule type"]
#         mqc.log(runlog, rule_info[rule]["QC test"])
#         inTrunk =  mqc.plinkBase(input.bedset[0])

#         subprocess.run([flashpca,
#                         "--bfile", inTrunk,
#                         "--outpc", output.ref_pcs,
#                         "--outmeansd", output.ref_meansd,
#                         "--outload", output.ref_loadings,
#                         "--outvec",  output.ref_eigenvec,
#                         "--outval", output.ref_eigenval,
#                         "--outpve", output.ref_var_explained ])

# This projection does not work (7.1.2020). Must look at this laters
# instead we rune one pca on a merged file, see below
# rule_stem = "pca_moba"               
# rule pca_moba:
#     input:
#         bedset = rules.common_markers_moba_ref.output.bedset_moba,        
#         ref_meansd = rules.pca_1kgp.output.ref_meansd,    # projected onto pca from ...
#         ref_loadings = rules.pca_1kgp.output.ref_loadings,# ... 1000 genomes pca
#     output:
#         moba_projection=tmpMod2/rule_stem/'projection_moba',
# # plot?        ref_meansd=tresultPath/rule_stem).with_suffix(".yaml"),
# #                         category="Module 2 1000Genomes prep",
# #                         caption=(resultPath/rule_stem).with_suffix(".rst"))

#     run:
#         item_type = rule_info[rule]["rule type"]
#         mqc.log(runlog, rule_info[rule]["QC test"])
#         inTrunk =  mqc.plinkBase(input.bedset[0])

#         # --project moba data onto 1000 genomes loading
#         subprocess.run([flashpca,
#                         "--bfile", inTrunk,
#                         "--project",
#                         "--inmeansd", input.ref_meansd,
#                         "--outproj", output.moba_projection,
#                         "--inload", input.ref_loadings
#         ])

rule_stem = "pca_both"
rule pca_both:
    input:
        bedset_ref = rules.common_markers_moba_ref.output.bedset_ref,        
        bedset_moba = rules.common_markers_moba_ref.output.bedset_moba,        
    output:
        bedset = expand(str(tmpMod2/rule_stem) + '{ext}', ext=['.bed','.bim','.fam']),
        pcs=tmpMod2/(rule_stem+".pcs"),
    benchmark:
        (tmpMod2/rule_stem).with_suffix(".benchmark")
    run:
        item_type = rule_info[rule]["rule type"]
        mqc.log(runlog, rule_info[rule]["QC test"])
        inTrunk_ref =  mqc.plinkBase(input.bedset_ref[0])
        inTrunk_moba =  mqc.plinkBase(input.bedset_moba[0])
        outTrunk =  mqc.plinkBase(output.bedset[0])

        subprocess.run([plinklocal,
                        "--bfile", inTrunk_ref,
                        "--bmerge", inTrunk_moba,
                        "--out", outTrunk,
                        "--make-bed"    ])

        subprocess.run([flashpca,
                        "--bfile", outTrunk,
                        "--outpc", output.pcs,
                        ])

        
# plots a projection, does not work well 7.1.2020 Delete or fix later, see plot_pca_both below  
# rule_stem = "plot_pca"        
# rule plot_pca:  
#     input:
#         pop_map = config["1000_genomes_pop"],       # maps samples to population-groups
#         ref_pcs = rules.pca_1kgp.output.ref_pcs,
#         moba_pcs = rules.pca_moba.output.moba_projection,

#     output:
#         plot = report((resultPath/rule_stem).with_suffix(".png"),
#                       category="Module 2 1000Genomes prep")
                      
#     run:
#         # To remove when this goes to mobaQcTools
#         import pandas as pd
#         import plotnine as p9
#         import matplotlib
#         matplotlib.use('Agg')  

#         pc = pd.read_csv(input.ref_pcs, usecols=['IID','PC1','PC2'],delim_whitespace=True)
#         moba = pd.read_csv(input.moba_pcs, usecols=['IID','PC1','PC2'],delim_whitespace=True)
#         # All data. We here later assume that moba ID and 1000 genomes ID are different
#         all = pd.concat([pc,moba],ignore_index=True) 

#         # Populations for colouring -
#         # see https://www.internationalgenome.org/faq/which-populations-are-part-your-study/ for details
#         pop = pd.read_csv(input.pop_map,usecols=['#IID','SuperPop','Population'],delim_whitespace=True)
#         # Simulate population for Moba
#         popmoba = pd.read_csv(input.moba_pcs,usecols=['IID'],delim_whitespace=True)
#         popmoba.columns = ["#IID"]  # rename to match earlier pop
#         popmoba['SuperPop'] = '->MoBa'
#         popmoba['Population'] = '->MoBa'
#         all_pop = pd.concat([pop,popmoba],ignore_index=True)
#         merged = pd.merge(left=all, right=all_pop, left_on='IID', right_on='#IID')
#         print(merged)
        

#         # Set up colours
#         # colours = {'EUR': 'red', 
#         #            'EAS': 'darkblue', 
#         #            'AMR': 'violet', 
#         #            'SAS': 'orange', 
#         #            'AFR': 'yellow', 
#         #            'Moba':'black'}
#         popc = "SuperPop"
#         p = p9.ggplot(data=merged, mapping=p9.aes(x='PC1',y='PC2',color=popc, shape=popc))
#         looks = p9.aes(color=popc, shape=popc)
#         p +=  p9.geom_point()
#         p += p9.scale_colour_brewer(type="qual", palette="Set1")  # better for colourblind
#         p9.ggsave(plot=p, filename=output.plot, dpi=600)

        
rule_stem = "plot_pca_both"        
rule plot_pca_both:  
    input:
        pop_map = config["1000_genomes_pop"],       # maps samples to population-groups
        pcs = rules.pca_both.output.pcs,            # principal components
        moba = mqc.plinkBase(rules.common_markers_moba_ref.output.bedset_moba[0]) + ".fam"

    output:
        plot = report((resultPath/rule_stem).with_suffix(".png"),
                      category="Module 2 Core samples and infere pedigree",
                      caption=(resultPath/rule_stem).with_suffix(".rst"))

    params: "Legend on https://www.internationalgenome.org/faq/which-populations-are-part-your-study/"
    benchmark:
        (tmpMod2/rule_stem).with_suffix(".benchmark")
    run:
        # To remove when this goes to mobaQcTools
        pc = pd.read_csv(input.pcs, usecols=['IID','PC1','PC2'],delim_whitespace=True)
        # Populations for colouring -
        pop = pd.read_csv(input.pop_map,usecols=['#IID','SuperPop','Population'],delim_whitespace=True)
        # Simulate population for Moba, read 2-column in fam-file
        popmoba = pd.read_csv(input.moba,usecols=[1], header=None,
                              delim_whitespace=True)
        popmoba.columns = ["#IID"]  # rename to match earlier pop
        popmoba['SuperPop'] = '->MoBa'
        popmoba['Population'] = '->MoBa'
        all_pop = pd.concat([pop,popmoba],ignore_index=True)
        merged = pd.merge(left=pc, right=all_pop, left_on='IID', right_on='#IID')
        # Explode Europe to Countries in Population
        merged.loc[merged['SuperPop'] == 'EUR', 'SuperPop'] = 'EUR_'+merged['Population']
        legend_info = params[0]
        # Set up colours   - no using this - did not get it right and dont want to spend time on it
        # colours = {'EUR': 'red', 
        #            'EAS': 'darkblue', 
        #            'AMR': 'violet', 
        #            'SAS': 'orange', 
        #            'AFR': 'yellow', 
        #            'Moba':'black'}
        popc = "SuperPop"
        p = p9.ggplot(data=merged, mapping=p9.aes(x='PC1',y='PC2',color=popc, shape=popc))
        #looks = p9.aes(color=popc, shape=popc)
        p +=  p9.geom_point()
        p += p9.scale_colour_brewer(type="qual", palette="Set1")  # better for colourblind
        p9.ggsave(plot=p, filename=output.plot, dpi=600)
        # create the caption usually made by saveYamlResults
        with open(str(resultPath/rule)+".rst", 'w') as file:
            file.write(f'Rule {rule_info[rule]["Rule order"]} ({rule_info[rule]["rule action"]})\n')
            file.write(f"{legend_info}\n")

rule_stem = 'extracted_pca_outliers'
rule extract_pca_outliers:
    input:
        bedset = rules.common_markers_moba_ref.output.bedset_moba,
        pcs = rules.pca_both.output.pcs,            # principal components
        moba = rules.plot_pca_both.input.moba,           # moba samples
    output:
        bedset=expand(str(tmpMod2/rule_stem)
                          + '{ext}', ext=['.bed','.bim','.fam']),
        exclude_list = (tmpMod2/rule_stem).with_suffix(".txt"),
        results = report((resultPath/rule_stem).with_suffix(".yaml"),
                         category="Module 2 Core samples and infere pedigree",
                         caption=(resultPath/rule_stem).with_suffix(".rst"))
    params:
        treshold = -0.05752391   # Stupid and visual - for now
    benchmark:
        (tmpMod2/rule_stem).with_suffix(".benchmark")
    run:
        item_type = rule_info[rule]["rule type"]
        mqc.log(runlog, rule_info[rule]["QC test"])
        mqc.log(runlog, "PCA exlude {item_type} ({params.treshold})\n")

        inTrunk =  mqc.plinkBase(input.bedset[0])
        outTrunk =  mqc.plinkBase(output.bedset[0])
        pca_treshold = params.treshold
        pc = pd.read_csv(input.pcs, usecols=['IID','PC1','PC2'],delim_whitespace=True)
        # List (only) moba samples that pca-wise are too spread
        mobasamples = pd.read_csv(input.moba,usecols=[0,1], header=None,
                                  delim_whitespace=True)
        mobasamples.columns = ["FID","IID"]
        # keep just moba-samples
        moba_pca = pd.merge(left=pc, right=mobasamples, left_on='IID', right_on='IID')

        # This is a superdirty hack to exclude the same number as samples as
        # was excluded by the hapmap pca. Must be replace by a sensible function
        # Samples to exclude found put in output.excludelist
        moba_pca.loc[(moba_pca.PC1 > params.treshold)].to_csv(output.exclude_list,
                columns=['FID','IID'],index=False, header=False, sep = ' ')
        
        subprocess.run([plinklocal,
                "--bfile",inTrunk,
                "--remove", output.exclude_list,
                "--out", outTrunk,  
                "--make-bed" ])

        dropouts = mqc.checkUpdates(inTrunk+".fam", outTrunk+".fam",cols = [0,1],
                                    sanityCheck = "removal", fullList = True)
        dropouts.update(rule_info[rule])   # Metainfo and documentation about the rule
        dropouts["Treshold"] = params.treshold
        dropouts["Rule"] = rule
        mqc.saveYamlResults(output.results, dropouts)
        
rule_stem = "extracted_pca_samples_from_full_markerset"
rule extract_pca_samples_from_full_markerset:
    input:
        samples = rules.extract_pca_outliers.output.bedset,
        markers = rules.pedigree_fu_detector_solver.output.inferped_all,
    output:
        bedset=expand(str(tmpMod2/rule_stem)
                          + '{ext}', ext=['.bed','.bim','.fam']),
        results = report((resultPath/rule_stem).with_suffix(".yaml"),
                         category="Module 2 Core samples and infere pedigree",
                         caption=(resultPath/rule_stem).with_suffix(".rst"))
        
    benchmark:
        (tmpMod2/rule_stem).with_suffix(".benchmark")
    run:
        item_type = rule_info[rule]["rule type"]
        mqc.log(runlog, rule_info[rule]["QC test"])
        mqc.log(runlog, "PCA exlude {item_type} ({params.treshold})\n")

        inTrunk =  mqc.plinkBase(input.markers[0])
        outTrunk = mqc.plinkBase(output.bedset[0])
        sample_list = mqc.plinkBase(input.samples[0]) + ".fam"
        print (f"using {inTrunk} to make {outTrunk} using {sample_list}")
        subprocess.run([plinklocal,
                "--bfile", inTrunk,
                        "--keep", sample_list,
                "--out", outTrunk,  
                "--make-bed" ])
        dropouts = mqc.checkUpdates(inTrunk+".fam", outTrunk+".fam",cols = [0,1],
                                    sanityCheck = "removal", fullList = True)

        dropouts.update(rule_info[rule])   # Metainfo and documentation about the rule
        dropouts["Rule"] = rule
        mqc.saveYamlResults(output.results, dropouts)

        
rule_stem = "split"
rule split_founder_offspring:
    input:
        bedset = rules.extract_pca_samples_from_full_markerset.output.bedset
    output:
        bedset_founder =expand(str(tmpMod2/"founders"/"start_clean") + '{ext}', ext=['.bed','.bim','.fam']),
        bedset_offspring =expand(str(tmpMod2/"offspring"/"start_clean") + '{ext}', ext=['.bed','.bim','.fam']),
        results_founder = report(str(resultPath/rule_stem)+"_founder.yaml",
                         category="Module 2 Core samples and infere pedigree",                      
                         caption=str(resultPath/rule_stem)+"_founder.rst"),
        results_offspring = report(str(resultPath/rule_stem)+"_offspring.yaml",
                         category="Module 2 Core samples and infere pedigree",                      
                         caption=str(resultPath/rule_stem)+"_offspring.rst")
    benchmark:
        (tmpMod2/rule_stem).with_suffix(".benchmark")
    run:
        item_type = rule_info[rule]["rule type"]
        mqc.log(runlog, rule_info[rule]["QC test"])
        inTrunk =  mqc.plinkBase(input.bedset[0])
        founderTrunk =  mqc.plinkBase(output.bedset_founder[0])
        offspringTrunk =  mqc.plinkBase(output.bedset_offspring[0])

        subprocess.run([plinklocal,
                        "--bfile", inTrunk,
                        "--filter-founders",
                        "--out", founderTrunk,
                        "--make-bed"  ])
        
        dropouts = mqc.checkUpdates(inTrunk+".fam", founderTrunk+".fam",cols = [1], sanityCheck = "removal", fullList = True) 
        dropouts.update(rule_info[rule])   # Metainfo and documentation about the rule
        dropouts["Rule"] = rule
        mqc.saveYamlResults(output.results_founder, dropouts)

        subprocess.run([plinklocal,
                        "--bfile", inTrunk,
                        "--filter-nonfounders",
                        "--make-founders",
                        "--out", offspringTrunk,                         
                        "--make-bed"  ])
        
        dropouts = mqc.checkUpdates(inTrunk+".fam", offspringTrunk+".fam", cols=[1], sanityCheck="removal", fullList=True) 
        dropouts.update(rule_info[rule])   # Metainfo and documentation about the rule
        dropouts["Rule"] = rule
        mqc.saveYamlResults(output.results_offspring, dropouts)

rule_stem = "ibd_prep"
rule ibd_prep:
    input:
        bedset = tmpMod2/"{role}/start_clean.bed",
        clean_snps = rules.prune_markers.output.exclude_list
    output:
        genome = (tmpMod2/"{role}"/rule_stem).with_suffix(".genome"),
        ibd_reduced_genome = tmpMod2/"{role}"/"ibd_reduced.genome",   #input for R laters, 3 columns of genome file
        preplot = (resultPath/"{role}"/rule_stem).with_suffix(".png")
    benchmark:
        (tmpMod2/"{role}"/rule_stem).with_suffix(".benchmark")
    run:
        item_type = rule_info[rule]["rule type"]
        mqc.log(runlog, rule_info[rule]["QC test"])
        inTrunk =  mqc.plinkBase(input.bedset)
        outTrunk =  mqc.plinkBase(output.genome)

        subprocess.run([plinklocal,
                        "--bfile", inTrunk,
                        "--extract", input.clean_snps,
                        "--genome",
                        "--out", outTrunk ])
        # create a plot for this
        p = mqc.dotplot(output.genome,prec=3, x='Z0',y='Z1', c='RT')
        p9.ggsave(plot=p, filename=output.preplot, dpi=600)
        df = pd.read_csv(output.genome, delim_whitespace=True, 
            usecols=["IID1", "IID2", "PI_HAT"] )
        df.to_csv(output.ibd_reduced_genome, index=False, sep=" ")

rule_stem = "ibd_exclusion"
rule ibd_exclusion:
    input:
        fam = tmpMod2/"{role}/start_clean.fam",
        ibd_reduced_genome = rules.ibd_prep.output.ibd_reduced_genome
    output:
        exclusion = (tmpMod2/"{role}"/rule_stem).with_suffix(".txt"),
        bedset = (tmpMod2/"{role}"/"allmarkers_pihat_accum").with_suffix(".bed"),
        plot = report((resultPath/"{role}"/"pihat_accum").with_suffix(".png"), # a hack as R produces the plot
                         category="Module 2 Core samples and infere pedigree"),
                         #, caption=str(resultPath/rule_stem)+"_{role}.rst"),
        results = report(str(resultPath/rule_stem)+"_{role}.yaml",
                         category="Module 2 Core samples and infere pedigree")
                         #, caption=str(resultPath/rule_stem)+"_{role}.rst"),
    params:
        pihat_thr = str(config["ibd_pihat_thr"]),
        hard_thr = str(config["ibd_hard_thr"])
    benchmark:
        (tmpMod2/"{role}"/rule_stem).with_suffix(".benchmark")     
    run:
        item_type = rule_info[rule]["rule type"]
        mqc.log(runlog, rule_info[rule]["QC test"])
        inTrunk =  mqc.plinkBase(input.fam)
        outTrunk =  mqc.plinkBase(output.bedset)
        plotdir = os.path.dirname(output.plot) + "/"  # The R script is sensible to this ...
        # for now, the below is not ported and lives it's own life
        subprocess.run(["Rscript",
                    f"{libdir}/accumPIHAT.R", 
                    input.ibd_reduced_genome,
                    input.fam,
                    output.exclusion,
                    plotdir,  
                    params.pihat_thr,
                    params.hard_thr ])
        subprocess.run([plinklocal,
                        "--bfile", inTrunk,
                        "--remove", output.exclusion,
                        "--make-bed",
                        "--out", outTrunk ])
        dropouts = mqc.checkUpdates(inTrunk+".fam", outTrunk+".fam",cols = [1],
                                    sanityCheck = "removal", fullList = True)
        dropouts.update(rule_info[rule])   # Metainfo and documentation about the rule
        dropouts["Rule"] = rule
        mqc.saveYamlResults(output.results, dropouts)

rule_stem = 'ibd_pruned'
rule ibd_prune:
    input:
        bedset = rules.ibd_exclusion.output.bedset,
        genome = rules.ibd_prep.output.genome
    output:
        bedset = (tmpMod2/"{role}"/rule_stem).with_suffix(".bed"),
        results = report((resultPath/"{role}"/rule_stem).with_suffix(".yaml"),
                         category="Module 2 Core samples and infere pedigree"),                         
                         # caption=(resultPath/rule_stem).with_suffix(".rst")),
        # in addition to the removal list, a removal.samples.txt is produced, sporting only the sample-list
        removal= (tmpMod2/"{role}"/rule_stem).with_suffix(".txt"),
        removal_samples = (tmpMod2/"{role}"/rule_stem).with_suffix(".samples.txt"),
    params:
        treshold = config['ibd_straight_thr']
    benchmark:
        (tmpMod2/"{role}"/rule_stem).with_suffix(".benchmark")
    run:
        item_type = rule_info[rule]["rule type"]
        mqc.log(runlog, rule_info[rule]["QC test"])

        inTrunk =  mqc.plinkBase(input.bedset)
        outTrunk =  mqc.plinkBase(output.bedset)
        # identify samples forremoval due to high PI_HAT
        (removed,total) = mqc.extract_list(input.genome, 
                output.removal_samples, output.removal, 
                colName="PI_HAT", sep=None, condition=">", treshold=params.treshold, 
                key_cols=[0,1], doc_cols=[0,1] )

        subprocess.run([plinklocal,
                "--bfile",inTrunk,
                "--remove", output.removal_samples,
                "--out", outTrunk ,
                "--make-bed"])
    

        dropouts = mqc.checkUpdates(inTrunk+".fam",outTrunk+".fam",cols = [0,1], sanityCheck = "removal", fullList = True) 
        dropouts.update(rule_info[rule])   # Metainfo and documentation about the rule
        dropouts["Treshold"] = params.treshold
        dropouts["Rule"] = rule
        mqc.saveYamlResults(output.results, dropouts)

        
rule_stem = 'geno_rates_mind3' # last iteration - keep <= 9 or fix code below
rule geno_rates:        # part of earlier markerclean
    input:
        bedset = rules.ibd_prune.output.bedset,
    output:
        # Result for every iteration, below is only the last
        bedset = (tmpMod2/"{role}"/rule_stem).with_suffix(".bed"),
        results = report((resultPath/"{role}"/rule_stem).with_suffix(".yaml"),
                         category="Module 2 Core samples and infere pedigree"),                         
                         # caption=(resultPath/rule_stem).with_suffix(".rst")),
        plots = report((resultPath/"{role}"/rule_stem).with_suffix(".png"),
                         category="Module 2 Core samples and infere pedigree"),                         
                         # caption=(resultPath/rule_stem).with_suffix(".rst")),                         
    params:
        #3 cycles of mind/geno removal
        geno1 = config["geno_rate.geno1"],
        mind1 = config["geno_rate.mind1"],
        geno2 = config["geno_rate.geno2"],
        mind2 = config["geno_rate.mind2"],
        geno3 = config["geno_rate.geno3"],
        mind3 = config["geno_rate.mind3"]
    benchmark:
        (tmpMod2/"{role}"/rule_stem).with_suffix(".benchmark")      
    run:
        item_type = rule_info[rule]["rule type"]
        mqc.log(runlog, rule_info[rule]["QC test"])

        inTrunk =  mqc.plinkBase(input.bedset)
        out_dir = Path(output.bedset).parent    # Directory according to output.bedset
        res_dir = Path(output.results).parent   # and corresponding for results
        lastTrunk = inTrunk
        # Iterate 3 times, greating a chain of geno1->mind1->geno2->mind2 etc files
        # We might have just as well off with cut'n paste here - the code is somewhat
        # hard to read - 
        for i in [1,2,3]:      # last number must max must match rule all:
            mqc.log(runlog, f'{rule_info[rule]["QC test"]}: Iteration {i}')
            print(f'{rule_info[rule]["QC test"]}: Iteration {i}')
            file_name= rule + "_geno" + str(i)
            outTrunk =  str(out_dir/file_name)
            res_file =  str(res_dir/file_name)+".yaml"
            plot_file =  str(res_dir/file_name)+".png"
            # Plink for both marker and samples, slightly different names for the params
            mqc.missing_genotype_rate(rule, lastTrunk, outTrunk, sample=False,
                                 treshold=getattr(params,f"geno{i}"),
                                      result_file=res_file,
                                      plot_file=plot_file)                                      

            lastTrunk = outTrunk
            file_name= rule + "_mind" + str(i)
            outTrunk =  str(out_dir/file_name)
            res_file =  str(res_dir/file_name)+".yaml"
            plot_file =  str(res_dir/file_name)+".png"
            mqc.missing_genotype_rate(rule, lastTrunk, outTrunk, sample=True,
                        treshold=getattr(params,f"mind{i}"),
                        result_file=res_file,
                        plot_file=plot_file)

            lastTrunk = outTrunk


rule_stem = 'hwe_autos_geno' # called clean_marker previously
rule hwe_autos_geno:        # part of earlier markerclean
    input:
        bedset = rules.geno_rates.output.bedset,
    output:
        bedset = (tmpMod2/"{role}"/rule_stem).with_suffix(".bed"),
        results = report((resultPath/"{role}"/rule_stem).with_suffix(".yaml"),
                         category="Module 2 Core samples and infere pedigree"),                         
                         # caption=(resultPath/rule_stem).with_suffix(".rst")),
        plots = report((resultPath/"{role}"/rule_stem).with_suffix(".png"),
                         category="Module 2 Core samples and infere pedigree"),                         
                         # caption=(resultPath/rule_stem).with_suffix(".rst")),                         
    params:
        #2 cycles hwe/maf + a geno 
        hwe1 = config["hwe1"],
        maf1 = config["maf1"],
        sd_het1 = config["sd_het1"],
        hwe2 = config["hwe2"],
        maf2 = config["maf2"],
        sd_het2 = config["sd_het2"],
        geno_rare = config["geno_rare"]
    benchmark:
        (tmpMod2/"{role}"/rule_stem).with_suffix(".benchmark")      
    run:
        item_type = rule_info[rule]["rule type"]
        mqc.log(runlog, rule_info[rule]["QC test"])

        inTrunk =  mqc.plinkBase(input.bedset)
        out_dir = Path(output.bedset).parent    # Directory according to output.bedset
        res_dir = Path(output.results).parent   # and corresponding for results
        lastTrunk = inTrunk
        # Iterate 2 times, greating a chain of geno1->mind1->geno2->mind2 etc files
        # We might have just as well off with cut'n paste here - the code is somewhat
        # hard to read -
        autosomal = "common"
        for i in [1,2]:    # common_het logic not suited for more than 2 iterations
            file_name= rule + "_hwe" + str(i)
            outTrunk =  str(out_dir/file_name)
            res_file =  str(res_dir/file_name)+".yaml"
            plot_file =  str(res_dir/file_name)+".png"
            # Filters and plots
            mqc.low_hwe_rate(rule, lastTrunk, outTrunk,  
                            treshold=getattr(params,f"hwe{i}"),
                            hwe_switches = ["--autosome", "--hardy", "midp"],
                            result_file=res_file,
                            plot_file=plot_file)                                      


            lastTrunk = outTrunk
            file_name= rule + "_het" + str(i)
            outTrunk =  str(out_dir/file_name)
            res_file =  str(res_dir/file_name)+".yaml"
            plot_file =  str(res_dir/file_name)+".png"
            mqc.excess_het(rule, autosomal, lastTrunk, outTrunk,  
                            treshold=getattr(params,f"maf{i}"),
                            sd=getattr(params,f"sd_het{i}"),
                            result_file=res_file,
                            plot_file=plot_file)
            # dirty, but with two iterations only this works ...
            autosomal = "rare"
            lastTrunk = outTrunk

        # a last round of marker removal
        outTrunk =  mqc.plinkBase(output.bedset)
        mqc.missing_genotype_rate(rule, lastTrunk, outTrunk, sample=False,
                        treshold=params.geno_rare,
                        result_file=output.results,
                        plot_file=output.plots)                                      


rule_stem = 'sex_check'
rule sex_check:
    input:
        bedset = rules.hwe_autos_geno.output.bedset,
    output:
        bedset = (tmpMod2/"{role}"/rule_stem).with_suffix(".bed"),
        results = report((resultPath/"{role}"/rule_stem).with_suffix(".yaml"),
                         category="Module 2 Core samples and infere pedigree"),                         
                         # caption=(resultPath/rule_stem).with_suffix(".rst")),
        # in addition to the removal list, a removal.samples.txt is produced, sporting only the sample-list
        removal= (tmpMod2/"{role}"/rule_stem).with_suffix(".txt"),
        removal_samples = (tmpMod2/"{role}"/rule_stem).with_suffix(".samples.txt"),
    params:
        female_treshold = config['sex_check_female'],
        male_treshold = config['sex_check_male']
    benchmark:
        (tmpMod2/"{role}"/rule_stem).with_suffix(".benchmark")
    run:
        item_type = rule_info[rule]["rule type"]
        mqc.log(runlog, rule_info[rule]["QC test"])

        inTrunk =  mqc.plinkBase(input.bedset)
        outTrunk =  mqc.plinkBase(output.bedset)

        mqc.sex_check(rule, input.bedset, output.bedset, f_treshold=0.2, m_treshold=0.8,
                  result_file=output.results)

        

# 		# additional run of marker missingness at 2%
# 		report_plots \
# 		        {params.outdir}/clean_het-rare \
# 			{params.repdir} \
# 		        "CLEANGENO4" L 0.02
# 		plink_remove_above_geno \
# 		        {params.outdir}/clean_het-rare \
# 		        0.020 \
# 		        {params.outdir}/clean_autosomes

# 		samples_end_clean=`wc -l {params.outdir}/clean_autosomes.fam | cut -d ' ' -f1`
# 	        log "samples_begin: $samples_begin_clean, samples end: $samples_end_clean"
# 		"""

# rule sexclean:
# 	input:
# 		base + '{role}/tmp/' + 'clean_autosomes.bed'
# 	output:
# 		base + '{role}/tmp/' + 'clean_markers.bim', # FINAL MARKERS
# 		stvars = base + '{role}/rep/' + 'storedvars_cleansex.txt',
#                 exclinds = base + '{role}/rep/' + 'exclusions_cleansex_ind.txt',
#                 exclsnps = base + '{role}/rep/' + 'exclusions_cleansex_snp.txt'
# 	params:
#                 plotdir = base + '{role}/rep/' + 'plots_cleansex/',
#                 instem = base + '{role}/tmp/' + 'clean_autosomes',
#                 outdir = base + '{role}/tmp/'
# 	shell:
# 		"""
# 		set -e

# 		source {libdir}/functions.sh
# 		source {libdir}/plink_wrapper_functions.sh
# 		libdir={libdir}
# 		plinklocal={plinklocal}

#                 PIPELINELOG={runlog}
#                 STOREDVARS={output.stvars}
#                 EXCLUSIONSI={output.exclinds}
#                 EXCLUSIONSS={output.exclsnps}
#                 PLOTDIR={params.plotdir}

#                 log "--- CLEAN CORE SEX ---"
#                 mkdir -p $PLOTDIR
# 		clear_store
		
# 		report_ninds {params.instem} "INTO_SEXCLEAN"
# 		report_nsnps {params.instem} "INTO_SEXCLEAN"

# 		store "INTO_SEXCLEAN_X" `grep -c ^23 {params.instem}.bim`
# 		store "INTO_SEXCLEAN_Y" `grep -c ^24 {params.instem}.bim`
# 		store "INTO_SEXCLEAN_PAR" `grep -c ^25 {params.instem}.bim`
# 		store "INTO_SEXCLEAN_MT" `grep -c ^26 {params.instem}.bim`

# 		# Check sample sex (declared vs. genotyped)
# 	        # 1. Input bedset (all or only sex-markers)
# 	        # 2. Female max Fstat (PLINK default 0.20)
# 	        # 3. Male min Fstat (PLINK default 0.80)
# 	        # 4. Full path to list of samples with PROBLEM according to PLINK check-sex
# 	        # 5. TMP folder
# 	        plink_checksex \
# 	                {params.instem} \
# 	                0.20 \
# 	                0.80 \
# 	                {params.outdir}/checksex_exclude \
# 	                {params.outdir}

# 	        # Remove samples failing sex-check
# 	        # 1. Input bedset stem
# 	        # 2. List of samples to remove (2 cols: PID IID)
# 	        # 3. Output bedset stem
# 	        # 4. Exclusion filter
# 	        plink_remove_samples \
# 	                {params.instem} \
# 	                {params.outdir}/checksex_exclude \
# 	                {params.outdir}/removed_failing_sexcheck \
# 	                "SEXCHECK"
	
# 	        ###--- CLEANING FEMALE X MARKERS ---###
# 	        # - Only chr. X/23
# 	        # note 1: all samples are now marked as FOUNDERS (no need for "--nonfounders" flag)
# 	        # note 2: all samples have missing phenotype (no need for "include-nonctrl" flag)
# 	        {plinklocal} \
# 	                --bfile {params.outdir}/removed_failing_sexcheck \
# 	                --filter-females \
# 	                --chr 23 \
# 	                --hardy midp \
# 	                --out {params.outdir}/females_x_hardy

# 	        # Getting the female X-markers below HWE threshold to be excluded
# 	        # NOTE: This step will generate a list of markers to remove in the final step
# 	        Rscript {libdir}/hwe_fail.R \
# 	                {params.outdir}/females_x_hardy.hwe \
# 	                0.000001 \
# 	                {params.outdir}/hwe_failed_female_x_markers \
# 	                ${{PLOTDIR}}hwe_x_chr.png
# 		store "TOREMOVE_HWE_X" `wc -l {params.outdir}/hwe_failed_female_x_markers`
	
# 	        ###--- CLEANING PAR-REGION IN BOTH GENDERS ---###
# 	        # - Using both males and females
# 	        # note: this could have beed done at autosomal stage by using "--autosome-xy"
# 	        {plinklocal} \
# 	                --bfile {params.outdir}/removed_failing_sexcheck \
# 	                --chr 25 \
# 	                --hardy midp \
# 	                --out {params.outdir}/par_hardy
	
# 	        Rscript {libdir}/hwe_fail.R \
# 	                {params.outdir}/par_hardy.hwe \
# 	                0.000001 \
# 	                {params.outdir}/hwe_failed_par_markers NA
# 		store "TOREMOVE_HWE_PAR" `wc -l {params.outdir}/hwe_failed_par_markers`
	
# 	        ###--- CLEANING MALE X ---###
# 	        # - Getting marker names on all markers with any heterozygous calls
# 	        touch {params.outdir}/male_x_exclusion_markers
# 	        awk 'FNR==NR{{if($1~/23/) x[$2]; next}} {{d[$3]++}}
# 	                END{{ for (s in d){{ if (d[s]>1 && s in x) print s }}}}' \
# 	                {params.outdir}/removed_failing_sexcheck.bim \
# 	                {params.outdir}/removed_failing_sexcheck.hh > {params.outdir}/male_x_exclusion_markers
	
# 	        ###--- REMOVE IDENTIFIED MARKERS FROM CORE ---###
# 	        cat {params.outdir}/hwe_failed_female_x_markers \
# 	            {params.outdir}/hwe_failed_par_markers > {params.outdir}/hwe_x_and_par_exclusions
	
# 	        #1. Input bedstem
# 	        #2. List of markers to exclude
# 	        #3. Output bedstem
# 	        #4. Exclusion filter
# 	        plink_exclude_markers \
# 	                {params.instem} \
# 	                {params.outdir}/hwe_x_and_par_exclusions \
# 	                {params.outdir}/sex_markers_removed_hwe \
# 	                "sex_marker_removal"
# 		store "AFTER_HWE_X" `grep -c ^23 {params.outdir}/sex_markers_removed_hwe.bim`
# 		store "AFTER_HWE_PAR" `grep -c ^25 {params.outdir}/sex_markers_removed_hwe.bim`

# 	        plink_exclude_markers \
# 	                {params.outdir}/sex_markers_removed_hwe \
# 	                {params.outdir}/male_x_exclusion_markers \
# 	                {params.outdir}/clean_markers \
# 	                "male_x_het"

# 		store "AFTER_SEXCLEAN_X" `grep -c ^23 {params.outdir}/clean_markers.bim`
# 		store "AFTER_SEXCLEAN_Y" `grep -c ^24 {params.outdir}/clean_markers.bim`
# 		store "AFTER_SEXCLEAN_PAR" `grep -c ^25 {params.outdir}/clean_markers.bim`
# 		store "AFTER_SEXCLEAN_MT" `grep -c ^26 {params.outdir}/clean_markers.bim`
# 		"""

# rule makecore:
# 	input:
# 		base + '{role}/tmp/' + 'starting_clean.bed', # PCA pass, split, all markers
# 		prunedsnps = base + 'both/tmp/' + 'prune_markers_tmp.prune.in', # from superclean above
# 		markerlist = base + 'both/tmp/' + 'shared_markers.txt'
# 	output:
# 		base + '{role}/tmp/' + 'core-lmm.bed',
# 		base + '{role}/tmp/' + 'core-supreme.bed',
# 		base + '{role}/pca/' + 'final_pca_covars.txt',
# 		stvars = base + '{role}/rep/' + 'storedvars_verify.txt',
# 		exclinds = base + '{role}/rep/' + 'exclusions_verify_ind.txt',
# 		exclsnps = base + '{role}/rep/' + 'exclusions_verify_snp.txt'
# 	params:
#  		plotdir = base + '{role}/rep/' + 'plots_verify/',
# 		instem = base + '{role}/tmp/' + 'starting_clean',
# 		pcadir = base + '{role}/pca/',
# 		repdir = base + '{role}/rep/',
# 		outdir = base + '{role}/tmp/'
# 	shell:
# 		"""
# 		set -e
# 		libdir={libdir}
# 		plinklocal={plinklocal}

# 		source {libdir}/functions.sh
# 		source {libdir}/plink_wrapper_functions.sh

# 		PIPELINELOG={runlog}
# 		STOREDVARS={output.stvars}
# 		EXCLUSIONSI={output.exclinds}
# 		EXCLUSIONSS={output.exclsnps}
# 		PLOTDIR={params.plotdir}
# 		mkdir -p $PLOTDIR

# 		report_ninds {params.instem} "START_VERIFY"
# 		report_nsnps {params.instem} "START_VERIFY"

# 		# extract markers that pass QC in both founders and offspring
# 		plink_extract_markers \
# 			{params.instem} \
# 			{input.markerlist} \
# 			{params.outdir}/starting_verify \
# 			"shared_pass"
		
# 		# MISS
# 		plink_remove_above_mind \
# 			{params.outdir}/starting_verify \
# 			0.02 \
# 			{params.outdir}/verify_mind
		
# 		# HET filter
# 		plink_remove_excess_het_common \
# 		        {params.outdir}/verify_mind \
# 		        0.01 \
# 		        4 \
# 		        {params.outdir}/verify_het-common \
# 		        {params.outdir}
# 		plink_remove_excess_het_rare \
# 		        {params.outdir}/verify_het-common \
# 		        0.01 \
# 		        4 \
# 		        {params.outdir}/core-lmm \
# 		        {params.outdir}

# 		# RELATED CORE IS READY HERE.

# 		# filter IBD
# 		$plinklocal \
# 			--bfile {params.outdir}/core-lmm \
# 			--extract {input.prunedsnps} \
# 			--genome \
# 			--out {params.outdir}/verify_ibd

# 		awk '{{print $2, $4, $10}}' {params.outdir}/verify_ibd.genome > {params.outdir}/verify_ibd_reduced.genome
# 		awk '{{print $5, $7, $8}}' {params.outdir}/verify_ibd.genome > {params.outdir}/verify_ibd_forplot.genome
		
# 		Rscript {libdir}/draw-pihat-plots.R \
# 		        {params.outdir}/verify_ibd_forplot.genome \
# 		        ${{PLOTDIR}}z1z0_before.png "TRUE"
		
# 		# Args:
# 		# 1. reduced .genome file (three columns)
# 		# 2. .fam which was used to generate .genome
# 		# 3. output ind list file
# 		# 4. a full path and name of TEXT REPORT (accumPIHAT of all samples)
# 		# 5. a PI_HAT threshold to ignore too-closely related pairs
# 		# 6. a hard-set (accumPIHAT) threshold to define outliers
# 		Rscript {libdir}/accumPIHAT.R \
# 		        {params.outdir}/verify_ibd_reduced.genome \
# 		        {params.outdir}/core-lmm.fam \
# 		        {params.outdir}/verify_accumulated_exclusions.txt \
# 		        $PLOTDIR \
# 		        0.2 0.015

# 		plink_remove_samples \
# 		        {params.outdir}/core-lmm \
# 		        {params.outdir}/verify_accumulated_exclusions.txt \
# 		        {params.outdir}/core-lmm_pihat_accum \
# 		        "PIHAT_ACCUM"
		
# 		####  STRAIGHTFORWARD RELATEDNESS
# 		# read .genome and remove 0.1 thr
# 		# Args:
# 		# 1. Input bedset
# 		# 2. PIHAT threshold
# 		# 3. Output bedset
# 		# 4. .genome filestem
# 		remove_related_above_pihat_threshold \
# 		        {params.outdir}/core-lmm_pihat_accum \
# 		        0.1 \
# 		        {params.outdir}/core-supreme \
# 		        {params.outdir}/verify_ibd

# 		# CORE-SUPREME IS READY HERE.

# 		$plinklocal \
# 			--bfile {params.outdir}/core-supreme \
# 			--extract {input.prunedsnps} \
# 			--make-bed \
# 			--out {params.pcadir}/pruned

# 		# Final PCA on the CORE-SUPREME
# 	        # 1. Input bedset (pre-pruned)
# 	        # 2. Output path + prefix of PCA output
# 	        # 3. TMP folder
# 	        pca \
# 	                {params.pcadir}/pruned \
# 	                {params.pcadir}/results \
# 	                {params.pcadir}
	
# 	        # Create a PLINK covariate files with PCs only
# 	        tail -n +2 {params.pcadir}/results.pca.evec | sed 's/^ *//' | tr -s ' ' ' ' | cut -f1-11 -d' ' | tr ':' ' ' > {params.pcadir}/final_pca_covars.txt
	
# 	        # Plot final PCA run
# 	        # 1. pcainput
# 	        # 2. outfile
# 	        Rscript {libdir}/plot_pca_without_hapmap.R \
# 	          {params.pcadir}/results.pca.evec \
# 	          {params.pcadir}/final_core_clean.png

# 	        # Create screeplot on final PCAs
# 	        # 1. Eigenvalues input file (the initial lines of the .pca output file from Eigenstrat)
# 	        # 2. Number of PCs (eg. will use the lines 2 to 11 if 10 PCs - the first line denotes number of PCs)
# 	        # 3. Plot header prefix
# 	        # 4. Output path of plot
# 	        # 5. Output name of plot pdf file
# 	        awk 'NR==1{{for(i=1; i<=NF; i++) print $i}}' {params.pcadir}/results.pca.evec > {params.pcadir}/results.pca
# 	        Rscript {libdir}/create_screeplot_pca.R \
# 	                {params.pcadir}/results.pca \
# 	                10 \
# 	                {wildcards.role} \
# 	                {params.pcadir} \
# 	                pca-final-screeplot.pdf
	
# 		"""

# # Rule to generate the exclusion and flag lists
# rule generate_lists:
#     input:
#         expand(base + '{role}/tmp/' + 'core-lmm.bed', role=ROLES),
#         expand(base + '{role}/tmp/' + 'core-supreme.bed', role=ROLES)
#     output:
#         exl_snp=config['output_base'] + 'exclusions_snp_long.txt',
#         exl_ind=config['output_base'] + 'exclusions_ind_long.txt',
#         flaglist=config['output_base'] + 'sample_flag_list.txt'
#     params:
#         input_dir=config['output_base']
#     shell:
#         """
# 	set -e
# 	source {libdir}/functions.sh

#         # Combines sample exclusion lists from one directory
#         # Args:
#         # 1. reporting dir/
#         # 2. current dataset name
# 	# 3. exclusion dir/
#         echo "FID IID FILTER STAGE BATCH" > {output.exl_ind}
#         echo "CHR SNP FILTER STAGE BATCH" > {output.exl_snp}

#         combine_dir {params.input_dir}mod1-data-preparation/rep/ "MOD1" {params.input_dir}
#         combine_dir {params.input_dir}both/rep/ "MOD2-BOTH" {params.input_dir}
#         combine_dir {params.input_dir}founders/rep/ "MOD2-FOUNDERS" {params.input_dir}
#         combine_dir {params.input_dir}offspring/rep/ "MOD2-OFFSPRING" {params.input_dir}
#         combine_dir {params.input_dir}mod5-shaping-preparation/rep/ "MOD5" {params.input_dir}

#         Rscript {libdir}/format_excl_table.R {params.input_dir}

#         """

rule_stem  = "rule_stem is only to be used in snakemake directives - have you used it in other code?"
